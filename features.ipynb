{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained Mask R-CNN model\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define a transformation to resize, normalize and convert images to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Function to get segmented parts of an image\n",
    "def get_segmented_parts(image_url):\n",
    "    # Load the image from the URL\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    \n",
    "    # Apply the transformations\n",
    "    img_t = transform(img)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    \n",
    "    # Pass the image through the model to get the detections\n",
    "    with torch.no_grad():\n",
    "        detections = model(batch_t)\n",
    "    \n",
    "    return detections[0], img\n",
    "\n",
    "# Function to visualize the segmented parts\n",
    "def visualize_segmented_parts(detections, img, threshold=0.5):\n",
    "    # Get the masks, labels, and scores\n",
    "    masks = detections['masks']\n",
    "    labels = detections['labels']\n",
    "    scores = detections['scores']\n",
    "    \n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Iterate over the masks\n",
    "    for i in range(masks.shape[0]):\n",
    "        if scores[i] >= threshold:\n",
    "            mask = masks[i, 0].mul(255).byte().cpu().numpy()\n",
    "            label = labels[i].item()\n",
    "            score = scores[i].item()\n",
    "            \n",
    "            # Create a colored mask\n",
    "            colored_mask = np.zeros_like(mask, dtype=np.uint8)\n",
    "            colored_mask[mask > 128] = 255\n",
    "            \n",
    "            # Overlay the mask on the image\n",
    "            ax.imshow(np.dstack((colored_mask, colored_mask, colored_mask)), alpha=0.5)\n",
    "            ax.text(detections['boxes'][i][0], detections['boxes'][i][1], f'{label} ({score:.2f})', \n",
    "                    bbox=dict(facecolor='yellow', alpha=0.5), fontsize=10, color='black')\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_url = 'https://www.russellandbromley.co.uk/ccstore/v1/images/?source=/file/v5011827438628642521/products/242458_xlalt4.jpg&height=800&width=800&quality=1.0'\n",
    "detections, img = get_segmented_parts(image_url)\n",
    "visualize_segmented_parts(detections, img)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
